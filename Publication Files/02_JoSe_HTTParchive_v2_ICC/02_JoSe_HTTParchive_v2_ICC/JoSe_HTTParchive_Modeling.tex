\documentclass[letterpaper,conference]{IEEEtran}
	
\ifCLASSINFOpdf
	\usepackage[pdftex]{graphicx}
	\graphicspath{{./figures/},{./dbfigs/}}
	\DeclareGraphicsExtensions{.pdf,.jpeg,.jpg,.png}
\else
	\usepackage[dvips]{graphicx}
	\graphicspath{{./figures/},{./dbfigs/}}
	\DeclareGraphicsExtensions{.eps}
\fi

% Convert eps to PDF on the fly
\usepackage[update,prepend]{epstopdf}

\usepackage[cmex10]{amsmath}
\interdisplaylinepenalty=2500
\usepackage{dblfloatfix}
\usepackage{url}

% *** SUBFIGURE PACKAGES ***
\ifCLASSOPTIONcompsoc
  \usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
\else
  \usepackage[caption=false,font=footnotesize]{subfig}
\fi

% for commenting etc
\usepackage[colorinlistoftodos,backgroundcolor=yellow,shadow]{todonotes}
\newcommand{\td}[1]{\todo[inline]{#1}}

%\IEEEoverridecommandlockouts

% Title Page
\title{Modeling Landing Page Characteristics for \\Mobile Web  Access Performance Evaluations on Object and Page Levels}
\author{\IEEEauthorblockN{Troy Johnson}
	\IEEEauthorblockA{Dept. of Computer Science\\
		Central Michigan University\\
		Mount Pleasant, MI 48859\\
		Email: johns4ta@cmich.edu}
	\and
	\IEEEauthorblockN{Patrick Seeling}
	\IEEEauthorblockA{Dept. of Computer Science\\
		Central Michigan University\\
		Mount Pleasant, MI 48859\\
		Email: pseeling@ieee.org}
}


\begin{document}
\maketitle

\begin{abstract}
As the main web page access modality shifts to mobile devices, evaluations of the impact on underlying networks is required to perform long--term strategic optimizations.
With individual mobile web page objects can be characterized by size, cache expiration, and their composition into pages, we evaluate their characteristics on an individual and composed page level.
Employing popular mobile web landing pages, we derive a model that captures their main facets with respect to object size and caching distributions on a lumped and contextually aggregated page level.
We observe that similar distributions can be employed for overall object sizes as well as their composition to web pages, while the cache expiration ages need to be taken into account for different contextual types of web pages.
Employing our model, we successfully approximate cache lifetimes for the mobile web.
Extrapolation by incorporating observed changes using only few parameters of our model enables its long--term validity for employment in mobile web performance evaluations.
\end{abstract}

\begin{IEEEkeywords}
	Mobile communication; traffic modeling; data communications
\end{IEEEkeywords}

\section{Introduction}

Smart mobile devices with ubiquitous connectivity have become popular worldwide and their utilization has increased the amount of traffic in wireless networks tremendously. 
As mobile users employ their always--present devices to access web--based services, additional forecasts include a shift of the main access of the world wide web from fixed desktops to mobile clients. 
Cisco, Inc. predicts that this current trend will result in a steady growth of mobile data for years to come~\cite{VNI14}.
As the primary means of web access changes, evaluations employing desktop client web access strategies not necessarily reflect the potential for optimizations.
While on the network provider side, caching can readily yield savings through caching~\cite{IhPa11}, the mobile client side becomes increasingly significant due to mobile devices typically exhibiting limitations with respect to battery capacities.
The composition of web pages, e.g., has an impact on battery consumption~\cite{ThAgNiBoSi12}.
Investigating the complexity of web pages, the number of loaded objects were found to positively correlate with the web page load times~\cite{BuMaSe13}, which, in turn will correlate with power consumptions.
Furthermore, in their evaluations the authors found that mobile and non--landing web pages tend to exhibit less complexity. 
In turn, landing pages of popular mobile web sites can be regarded as an upper complexity limit for approximations.

Recent evaluations of web page characteristic developments over time for landing pages of popular fixed and mobile web sites in~\cite{JoSe14Commag} found that mobile versions exhibit around 60 objects and are approaching one Megabyte in size on initial view. 
Images, other media elements (such as Flash or fonts), and Java Script objects were found to be the main overall size contributors.
While energy savings were found to be possible through pre--fetching and caching throughout the mobile age (see, e.g., \cite{SaIs02, ShKuDaWa05,ThChWo13}),
lower cache hit ratios can significantly reduce or inverse potential benefits, see, e.g., \cite{Wang:2012ks,Marquez:2008wf}.
Increasing the difficulty for efficient reduction of wireless network transmissions, a significant portion of web page objects was found to exhibit very short or no cache life time, resulting in additional downloads over the air interface, see, e.g., \cite{JoSe14Commag,Qian:2014dw,JoSe14GreenComm}.
The over--arching problem for higher--level optimization approaches on the mobile client and network sides is to provide a means to model the defining characteristics of web pages requested by mobile device browsers. 
In this contribution, we evaluate the modeling of mobile web pages using a public dataset of popular web pages accessed with a mobile (iPhone) client with respect to their number of objects, sizes, and caching abilities.
We approach this problem for the mobile web by focusing on landing pages as upper limit approximation, following the findings in~\cite{BuMaSe13}.
Throughout this paper, we assume that for caching purposes, only time frames up to a week have the most impact.

The remainder of this paper is structured as follows.
In the following section, we describe the underlying datasets and related metrics. 
We subsequently describe and evaluate the low--level characteristics and approximations for the individual web page objects contained in the dataset in Section~\ref{s:object}.
Section~\ref{s:page} follows with a web page--level approximation.
We present an evaluation of our model in Section~\ref{s:eval} before we conclude with an outlook on future works in Section~\ref{s:conc}.


\section{Web Page data sets}
\label{s:data}
We utilize the \url{httparchive.org} data sets of captured web performance metrics, which are publicly available. 
Each of the data sets is generated from initial client views (eliminating caching) of a broad set of popular web sites, which were determined based on the Alexa popularity ranking, accounting for almost 5000 landing pages. 
While the httparchive project gathers and archives the statistics of popular mobile web landing pages, these can be seen as representative upper boundaries of the evaluated characteristics when considered in conjunction with the observations in, e.g.,  \cite{BuMaSe13}.
We utilize the mobile data sets available for Oct. 15, 2013 as our main starting point, but limit the data set to object sizes of at least one byte (e.g., omitting redirects or other types of HTTP messages) and objects exhibiting a cache lifetime of at most one week.

\subsection{Summary of Data Set Characteristics} 

\td{
Table needs update with object-level and page-level characteristics from the right date
}

We denote the number of objects as $o$, the number of their requests for a web page as $o_p$, and the related average as $\overline{o_p}$. 
Similarly, we evaluate the individual object size as $x_o$ and their aggregated sum on an entire web page as $x_p$. 
We additionally investigate the average request size as $\frac{x}{r}$. 
Furthermore, we evaluate the cache expiration age for individual objects as $t_o$, denoted when in a web page context as $t_o^p$. The fraction of objects with a zero maximum age in cache (download every time) is denoted as $c_o(0), c_o^p(0)$ and those with potential for caching as $c_o,c_o^p$ on independent object and within page contexts.
We indicate the variability amongst the 4776 pages with 289335 valid object URLs evaluated within the data set employing the Coefficient of Variation (CoV). 
The results are provided in Table~\ref{tab:res} for the individual objects and complete mobile web pages.
\begin{table}[h!]
	\centering
	\caption{Comparisons of the average characteristics $\overline{(\cdot)}$ and the Coefficient of Variation CoV$(\cdot)$ for individual web page objects of the entire data set and the resulting web pages.\label{tab:res}}
	\begin{tabular}{|l||c|c||c|c|}
		\hline
		Metric                    & \multicolumn{2}{|c||}{Objects} & \multicolumn{2}{|c|}{Pages} \\
		& $\overline{(\cdot)}$ &  CoV$(\cdot)$  & $\overline{(\cdot)}$ & CoV$(\cdot)$ \\ \hline
		Object req. $o, o_p$            &        116.4         &     0.838      &          61          &    0.946     \\ \hline
		Sizes $x_o,x_p$ (MB)        &         1.56         &     1.263      &         0.85         &    1.245     \\ \hline
		Bytes/req. $x/r$ (kB)     &        14.76         &     1.537      &        14.57         &    0.869     \\ \hline
		Zero cache fraction $c_o(0),c_o^p(0)$ &        0.412         &     0.246      &        0.450         &    0.702     \\ \hline
		Cache fraction $c_o,c_o^p$        &        0.588         &     0.172      &        0.550         &    0.575     \\ \hline
	\end{tabular}
\end{table} 

We observe that the average number of requests is approximately twice as high for desktop versions when compared to their mobile counterparts. Similarly, the average desktop web page size is almost twice as large in size as well. The resulting average request sizes are in turn almost the same, independent of the accessing client's type.
We furthermore note that the variability within the data set is fairly low and close between the two versions for the number of requests and the average page sizes.
We find that the average request sizes are exhibiting a more significant variability for the desktop version. 
Shifting the view to the possibility of reducing network traffic through caching, we note that the fraction of items that have a max. age of zero as determined through the \url{httparchive.org} processing account for a significant portion of all data for both clients alike. These items in turn can be seen as the dynamically changing content requiring frequent refreshes and constitute just above 40\% of the items accessed by the web clients.

We note that throughout this paper, we illustrate the results using an aggregation level of 1000 bytes for object sizes and 900 seconds for object expiration ages for visual clarity only (i.e., not impacting underlying calculations).

\subsection{Evaluation of Object-- and Page level Dependencies}
We evaluate the dependencies of cache lifetimes, object sizes, as well as their aggregation into pages in Figure~\ref{fig:rel}.
\begin{figure}[]
	\centering
	\subfloat[Individual mobile web page objects	\label{fig:orel}]{\includegraphics[width=.35\textwidth,angle=270]{scatterplots/overall_2d_scatterplot_respSizes_expAges}}
	\qquad
	%
	\subfloat[Mobile Web Pages \label{fig:prel}]{\includegraphics[width=.5\textwidth]{scatterplots/scatter}}
	%
	\caption{Individual object and page--level relationships of sizes and cache expirations for mobile web landing pages.\label{fig:rel}}
\end{figure}
Initially, we observe that the distribution of object sizes over their lifetime is spread across the entire range of evaluated times. 
We secondly note that at specific expiration times, i.e., none, hour, day, etc., a broader range and aggregation of objects can be observed. 
While we do not observe a close correlation of object sizes and their cache lifetimes, we note that large numbers of even large sized objects have a very short lifetime.

Next, we evaluate the aggregated sizes on a page level in Figure~\ref{fig:prel}, whereby we focus on the range of below 100 objects, expiration below the first several days of a week, and up to 100 kB object sizes.
We observe that the majority of web pages in this group exhibits a low average expiration age ans well as a generally small average object size.
We additionally observe that the number of objects on a web page is fluctuating widely for this data set.
Overall, we do not observe a direct relationship between the number objects, their overall sizes, and their expiration ages once we evaluate them contextually combined on the web page level.
We employ this observation in the following modeling approach.


\section{Object--Level Modeling}
\label{s:object}
The initial modeling approach targets the level of individual objects as present in the entire data set, i.e., across all mobile web pages. 
This approach hence would be suitable for high--level modeling of mobile web traffic characteristics.

\subsection{Object Sizes}
The individual object sizes follow a Weibull minimum distribution, which we employ to randomly draw individual object sizes $x_o$ as defined by 
\begin{equation}\label{eq:weibull}
f(x_o) = \frac{a}{\lambda} \left(\frac{x_o}{\lambda}\right)^{a-1} \cdot e^{-(x_o/\lambda)^a}, 
\end{equation}
with $x_o>0, \alpha>0$.
We identified the shape parameter as $a \cong  0.573$ and the scale parameter as $\lambda \cong 8887.5$.
We illustrate the results from 500 evaluations in Figure~\ref{fig:osize}, noting that we omit the illustration of the confidence intervals for readability (they are typically within ten percent of the original value).
\begin{figure}
	\centering
	\includegraphics[width=.35\textwidth,angle=270]{respSizes/Overall/overall_respSizes}
	\caption{Real data set and synthetically generated web page object sizes across the entire data set.}
	\label{fig:osize}
\end{figure}
We observe that both distributions peak at a small response size on drop immediately, with the simulated web page object sizes following the trend of the underlying data set closely.
Due to the nature of the selected Weibull distribution for simulation purposes, the smaller abrupt changes in the distribution of sizes visible for the source data, e.g. between object sizes of 10 kB and 20 kB, are not captured in the modeled distribution.
We reason that the tractability and otherwise close fit, however, outweigh the capturing of these minor irregularities.

\subsection{Object Expiration Ages}
Next, we evaluate the capturing of the expiration ages, i.e., the maximum cache lifetime, of the individual web objects found in the dataset.
The underlying notion of web server configurations exhibits a non--linear relationship between the individual object expiration times set $t_o$, whereby common time frames, such as mandatory hourly or daily refreshes of individual objects are common. 
In turn, the modeling of this particular behavior follows a piecewise approximation, which distributes the expiration ages based on their original frequency in the underlying data set within the one week time interval we consider here.
Denoting $U(a,b)$ as continuous uniform distribution between inclusive $a$ and $b$ and $U[a,b]$ its discrete counterpart, we model the mobile web object expiration times by initially drawing $\tau_o \sim U(0,1)$ randomly.
We subsequently determine the expiration age $t_o$ for the object under consideration as in Eq.~\ref{eq:t0}.
\begin{equation}\label{eq:t0}
t_o =
\begin{cases}
0 ~\mathrm{for}~ 0 \le \tau_o <  0.6108,\\
300 ~\mathrm{for}~ 0.6108 \le  \tau_o < 0.6235,\\
600 ~\mathrm{for}~ 0.6235 \le \tau_o < 0.6353,\\
900 ~\mathrm{for}~ 0.6353 \le \tau_o < 0.6460,\\
3600 ~\mathrm{for}~0.6460 \le \tau_o < 0.6887,\\
7200 ~\mathrm{for}~0.6887 \le \tau_o < 0.6970,\\
14400 ~\mathrm{for}~0.6970 \le \tau_o < 0.7070,\\
21600 ~\mathrm{for}~0.7070 \le \tau_o < 0.7152,\\
43200 ~\mathrm{for}~0.7152 \le \tau_o < 0.7333,\\
86400 ~\mathrm{for}~0.7333 \le \tau_o < 0.8037,\\
172800 ~\mathrm{for}~0.8037 \le \tau_o < 0.8126,\\
604800 ~\mathrm{for}~0.8126 \le \tau_o < 0.8909,\\
U[0, 604800]~\mathrm{otherwise}.
\end{cases}
\end{equation}

We illustrate the original data set and simulated values in Figure~\ref{fig:oexp}.
\begin{figure}[b]
	\centering
	\includegraphics[width=.35\textwidth,angle=270]{expAges/Overall/overall_expAges}
	\caption{Real data set and synthetically generated web page object expiration ages across the entire data set.}
	\label{fig:oexp}
\end{figure}
We observe that the original expiration times exhibit several ``spikes'' of higher probability at the common time instances for mandatory cached element refreshes. 
Rather than fully capturing the detailed characteristics for the entire time scale, our model approaches the generally compartmentalized structure of expiration times especially for the shorter time scales of common values and coarsely approximates the longer tail end with smaller numbers of objects.

\section{Page--Level Modeling}
\label{s:page}
The modeling of the web pages is based on the combination of modeling the number of objects, their sizes, and their expiration times.
In contrast to the individual object level, we now need to consider the mobile web page--level context for the expiration age distributions, especially those objects that cannot be cached.
In the following, we present the individual model approach by the respective component.

\begin{figure}[t!]
	\centering
	\subfloat[Average number of objects per mobile web page	\label{fig:preq}]
	{\includegraphics[width=.35\textwidth,angle=270]{numResponses/numResponses}}
	\qquad
	%
	\subfloat[Mobile web page sizes\label{fig:psize}]
	{\includegraphics[width=.35\textwidth,angle=270]{respSizes/PageLevelTotal/page_level_sum_respSizes}}
	\qquad
	%
	\subfloat[Average mobile web page object expiration\label{fig:pexp}]
	{\includegraphics[width=.35\textwidth,angle=270]{expAges/PageLevelAverages/PageLevelexpAgeAverage/page_level_average_expAges}}	
	%
	\caption{Page--level simulation of mobile web landing pages for the October 15, 2013 data set.\label{fig:pages}}
\end{figure}

\subsection{Number of Objects per Page}
The evaluation of the aggregated object numbers ${o}_p$ for the individual pages $p$ indicates a distribution that follows a general Gamma distribution as 
\begin{equation*}\label{eq:gg}
f(o_p) = \frac{ k \cdot (o_p-\gamma)^{\kappa\alpha-1} }{\beta^{\kappa\alpha}\Gamma(\alpha)}e^{-\left(\frac{o_p-\gamma}{\beta}\right)^\kappa},
\end{equation*}
whereby we determine the two shape parameters as $\alpha=3.1119, \kappa=0.6167$, the scale parameter $\beta=8.2912$, and the location parameter as $\gamma=0.17238$.
%
%def gen_numResponses():
%#Gamma distribution parameters
%k = 0.6167 #shape parameter
%alpha =  3.1119 #shape parameter
%beta =  8.2912 #scale
%loc = 0.17238 #loc
%return int(math.ceil(ss.gengamma.rvs(alpha,k,loc = loc,scale=beta,size=1)[0]))â€‹
We illustrate the resulting outcome in Figure~\ref{fig:preq} as comparison between original and simulated data, as well as the  width of the confidence interval width in relation to the simulated data.
We observe that the average number of objects per page in both the original and simulates page--level data sets exhibit the same sharply rising distribution with a following larger tail of pages comprised of more than 25 objects.
We furthermore observe that the relative confidence interval width exhibits an increasing trend as the number of objects increases up to about 8 \%. 
This trend originates in the increasingly smaller probabilities of attaining a high number of web page elements. In turn, small deviations have an increasing impact on this relative performance metric. 



\subsection{Average Mobile Web Page Size}
With the determined number of objects in a page, the next step considers the determination of the individual web page object sizes.
The individual object size on the page level is determined in a next step by employing a Weibull distribution (as in Equation~\ref{eq:weibull}) with $a=0.27 ,\lambda=700$, and location adjusted by 2.5.
The resulting sum of mobile web landing page objects is illustrated in Figure~\ref{fig:psize}.
We observe that the page size distribution for both original and simulated data  exhibits the same trend of mostly smaller web page sizes paired with a long tail end.
The most notable difference between the two data sets occurs in the range of smaller web page sizes below 500 kB, where the original data has a less pronounced peak than the simulated data.
The relative confidence interval values follow the same trend we previously observed in Figure~\ref{fig:preq} for the number of requests with an increase as sizes and their respective probability.
We follow the prior reasoning that the significantly reduced probability towards the tail end is responsible for this increasing trend.  


\subsection{Average Mobile Web Page Expirations}
As a last step, we determine the expiration ages for the individual web page objects, but now with a contextual consideration for their distribution within the underlying mobile web pages as $t_o^p$.
We separate pages into different categories as ($i$) current, ($ii$) short--lived, ($iii$) medium--lived, and ($iv$) regular.

\subsubsection{Current Pages}
Current pages are characterized by all of their objects exhibiting a zero cache lifetime, and thus require extensive downloads. 
They account for approximately 6.3 \% of the pages in the simulated data set.

\subsubsection{Short--lived Pages}
This page category exhibits a low expiration age for all its objects and accounts for approximately 24.1 \% of all pages.
The expiration age for all objects is determined following the piece--wise approach in Equation~\ref{eq:t0}, but with modified ranges and probabilities as in Equation~\ref{eq:t1} as 
\begin{equation}\label{eq:t1}
t_o^p =
\begin{cases}
300 ~\mathrm{for}~ 0 \le \tau_o < 0.088, \\
1200 ~\mathrm{for}~ 0.088 \le \tau_o < 0.158, \\
1800 ~\mathrm{for}~0.158\le \tau_o < 0.246,\\
3600 ~\mathrm{for}~0.246 \le \tau_o < 0.351,\\
7200 ~\mathrm{for}~0.351 \le \tau_o < 0.404,\\
14400 ~\mathrm{for}~0.404 \le \tau_o < 0.456,\\
21600 ~\mathrm{for}~0.456 \le \tau_o < 0.474,\\
U[0, 604800]~\mathrm{otherwise}.
\end{cases}
\end{equation}

\subsubsection{Medium-lived Pages}
The long--lived page category exhibits a heavier tail for the expiration ages of its objects.
In turn, we employ a log--logistic distribution to model the expiration ages of all objects as 
\begin{equation*}
f(t_o^p)=\frac{\beta}{\alpha} \left(\frac{x-\gamma}{\alpha}\right)^{\beta-1}\left(1+\left(\frac{x-\gamma}{\alpha}\right)^\beta\right)^{-2},
\end{equation*}
whereby we set scale parameter $\alpha \approx 0.889 $, shape parameter $\beta \approx 2600.7$, and location parameter $\gamma=1$. 
When drawing a random expiration age, we limit the upper end of expiration ages to 43200.

\subsubsection{Regular Pages}
Regular pages account for the majority 63.3 \% of the simulated web pages. 
Their simulation is a two--step process, which initially determines the number of non--cacheable objects $o^0_p \in [0,1]$ as a sample from a normal distribution with $\lambda \approx 0.629, \sigma \approx 0.301$.
In a second step, the remaining expiration ages are set according to 
\begin{equation}\label{eq:t2}
t_o =
\begin{cases}
	0	~\mathrm{for}~	0.000	\le \tau_o <	0.611,                \\
	43200	~\mathrm{for}~	0.611	\le \tau_o <	0.629,            \\
	U[43201,86400]	~\mathrm{for}~	0.629	\le \tau_o <	0.641,   \\
	86400	~\mathrm{for}~	0.641	\le \tau_o <	0.885,            \\
	U[86401,172800]	~\mathrm{for}~	0.885	\le \tau_o <	0.889,  \\
	172800	~\mathrm{for}~	0.889	\le \tau_o <	0.898,           \\
	U[172801,259200]	~\mathrm{for}~	0.898	\le\tau_o <	0.900, \\
	259200	~\mathrm{for}~	0.900	\le \tau_o <	0.908,          \\
	U[259201,604800]	~\mathrm{for}~	0.908	\le \tau_o <	0.922, \\
	604800	~\mathrm{otherwise}.
\end{cases}
\end{equation}

Comparing the thus generated expiration times with those found in the original data set in Figure~\ref{fig:pexp}, we observe that the average page object expiration ages follow the same decreasing trend.
We furthermore note that the underlying data set exhibits a significantly higher level of variability in the average page object expiration ages than the simulated data. 
Additionally, we also observe that the simulated data features a slightly increased probability of shorter average expiration ages up to a day.
We note that the relative confidence interval width increases from very narrow to a steady 20 \% of the simulated data 
for the tail end of the average page level expiration ages. 
As visible, here the underlying dataset itself exhibits significant variability, which together with the lower probabilities can be regarded as the main source for the heightened relative confidence interval width.

\section{Evaluation}
\label{s:eval}
We now employ our model in two scenarios, whereby we evaluate its capability to capture web caching characteristics as outlined in, e.g., \cite{JoSe14GreenComm} as well as its suitability to react to changes of the mobile landing web page characteristics over time as outlined in, e.g., \cite{JoSe14Commag}, through simulations.

\begin{figure*}[h]
	\centering
	\subfloat[June 15, 2013]
	{\includegraphics[width=.22\textwidth,angle=270]{modeling_months_cache/jun13/mobile_bytes_graphs}}
	\label{fig:simjun13}
	%\qquad
%
	\subfloat[October 15, 2013]
	{\includegraphics[width=.22\textwidth,angle=270]{modeling_months_cache/oct13/mobile_bytes_graphs}}
	\label{fig:simoct13}
	%\qquad
%
	\subfloat[March 15, 2014]
	{\includegraphics[width=.22\textwidth,angle=270]{modeling_months_cache/mar14/mobile_bytes_graphs}}
	\label{fig:simmar14}
%
	\caption{Results from evaluations 1000 cache simulations employing the model for Oct. 15, 2013 and employed parameter estimations for June 2013 and March 2014.\label{fig:simpages}}
\end{figure*}

\subsection{Capturing Web Cache Characteristics}
We initially assume that all web pages in the data set have to be cached and evaluate the amount of resulting data that remains in the cache, employing our model in 1000 simulations. 
We compare the results to the original dataset in Figure~\ref{fig:simoct13}.  
(We additionally note that we omit confidence intervals for clarity, as their width is typically within 1 \%).
We observe that the original cached data amount quickly reduces to only about 45 \%, which is attributed to the frequent immediate expiration of objects.
As time progresses, the amounts of data that remain in the cache exhibit a staircase behavior, increasing at common time boundaries, such as an hour or a day.
We note that the simulated cached contents are initially underestimated, by a margin of about 10 \%. 
As time progresses, the model--based estimation follows the original data's trend and slightly underestimates the cached data amounts approximately after 30 minutes.
We observe that the underestimation, however, remains close to the original data, with deviation peaking around 5 \%.
Overall, we conclude that our model successfully captures the overall trend for the composition of mobile landing web pages, including the approximation of cached amounts data over time. 

\subsection{Capturing Trends over Time}
We evaluated the parameters of our model's approximation from September 15, 2013 to August 15, 2015 and determine a general linear trend as follows. 
Assuming similar distributions for object cache expiration times and numbers, we adjust the sizes of objects per modeled page based on linear interpolation for Equation~\ref{eq:weibull}. 
Specifically, we determined an increase of the shape parameter $\alpha$ by 0.0003 every two weeks and scale parameter $\lambda$ by approximately 106 during the same time. 
We illustrate the application of this straightforward interpolation by employing our model for the data of June 15, 2013 and March 15, 2014 in Figures~\ref{fig:simjun13} and \ref{fig:simmar14}, respectively.

We observe that the underlying original data sets exhibit a similar behavior than observed for the October data set in Figure~\ref{fig:simoct13}.
Specifically, they exhibit similar step--wise increases of the expired amounts of data over time as well as their comparative values, corroborating our earlier observations. 
Comparing the simulated web page amounts of data in the cache with those from the underlying data sets, we note that the basic linear prediction of the object sizes successfully captures the overall resulting trends caused by the underlying shifts of data described in \cite{JoSe14Commag}.




\section{Conclusion}
\label{s:conc}
We described an approximation to model the behavior of popular mobile web landing pages, which are used as upper limit approximation of data that can be expected to require networked delivery to mobile clients.
Our model is based on the assumption that the distribution of object expirations over time does not change significantly as time progresses, but the composition of web pages rather is sensitive to size changes.

We employ this approach to derive a time--independent approach to the application of our model, which is able to predict the cached amounts or downloaded amounts that are required when considering a large number of popular web pages.
As our model slightly under--estimates the amount of data remaining in a potential cache for up to 30 minutes, its resulting output can be readily applied in that time frame, whereas larger time frame model outputs slightly overestimate the cached amount and require discounting.
In future works, we intend to evaluate the model on a finer--grained approach, incorporating the different types of objects constituting the simulated mobile pages.


%\section*{Acknowledgment}
%This work was supported in part by an Early Career grant from the Office of Research and Sponsored Programs at Central Michigan University.

\bibliographystyle{IEEEtran}
\bibliography{content}

\end{document}
